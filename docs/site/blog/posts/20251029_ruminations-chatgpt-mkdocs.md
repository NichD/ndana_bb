---
title: Ruminations on Progress - Using AI to Co-Develop Builder Hub
slug: ruminations-ai-mkdocs
date: 2025-10-29
category: Reflection
tags:
  - reflection
  - mkdocs
  - builder-hub
  - ai
---

## Introduction

This is not a material update on progress. Rather this post contains some reflections having worked with AI tools in various domains and some observations of those experiences.

## Main Content

I've been using AI as a co-development tool for roughly a year now. Like many folks, I initially approached it with a mixture of excitement and anxiety. There's no question how much potential it has, and I've unambiguously accelerated my data science work using it, both as a conversant to discuss ideas (akin to a white board), and to auto-generate code for different software projects.

My use of these tools as coding assistants has focused on the data science domain, where I have considerable subject mastery. My domain knowledge there has allowed me to swiftly identify and diagnose issues with the output from generative AI, and problems were resolved swiftly with minimal iteration.

However, in this web-app domain, where my domain knowledge is lacking, I've often found the 'expertise' of generative AI tools lacking. This experiences echoes one side of a larger discussion, as to whether AI tools will render software devs, data scientists, business analysts and so on obsolete. I absolutely harbor concerns about maintaining my relevancy in the face of these rapidly advancing tools (that may seem difficult to believe, given my academic background, but it's true!).

Now, having had a year of experience working with these tools, and seeing their rapid advancement, my anxiety is somewhat tempered. My experience tells me that these tools (off the shelf) have great overall domain knowledge, but they lack discernment. Discernment is particularly important when resolving conflicts, addressing bugs, or evaluating different solutions. In this context, discernment is critical to the execution of a solution based on insight and good judgement - and these tools often lack that discernment.

It's particularly interesting that, when things begin to deviate from an optimal outcome (e.g. an AI proposed solution fails to address an issue), there's almost a positive-feedback process. I've seen this where the previous attempted solutions are not reverted, but rather 'fixes' are continually layered on, often exacerbating the problem. I find this very interesting and will explore ways to discourage this behavior, but it does afford me some comfort that I'm not entirely replacable _yet_.

## Takeaways

AI tools are amazing multipliers, but they lack discerment and valid experiential insight. These key attributes are often requisite to get something from 80% to 100% functional and represent that gap where skilled, knowledgeable humans are still necessary (for now). 